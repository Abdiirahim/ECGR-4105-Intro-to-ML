{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries (if not already installed)\n",
        "!pip install torch torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwu2PeT0RVKw",
        "outputId": "8b84f1b2-dd4f-4bdc-d7a5-aaf982057542"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je1_iOnNQhAK",
        "outputId": "01f84c40-ecc2-42d0-de5b-f42020a708ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch [1/200], Loss: 1.3382\n",
            "Epoch [2/200], Loss: 0.9676\n",
            "Epoch [3/200], Loss: 0.8095\n",
            "Epoch [4/200], Loss: 0.6985\n",
            "Epoch [5/200], Loss: 0.6074\n",
            "Epoch [6/200], Loss: 0.5237\n",
            "Epoch [7/200], Loss: 0.4463\n",
            "Epoch [8/200], Loss: 0.3760\n",
            "Epoch [9/200], Loss: 0.3158\n",
            "Epoch [10/200], Loss: 0.2678\n",
            "Epoch [11/200], Loss: 0.2214\n",
            "Epoch [12/200], Loss: 0.1861\n",
            "Epoch [13/200], Loss: 0.1628\n",
            "Epoch [14/200], Loss: 0.1376\n",
            "Epoch [15/200], Loss: 0.1273\n",
            "Epoch [16/200], Loss: 0.1153\n",
            "Epoch [17/200], Loss: 0.1031\n",
            "Epoch [18/200], Loss: 0.0998\n",
            "Epoch [19/200], Loss: 0.0856\n",
            "Epoch [20/200], Loss: 0.0948\n",
            "Epoch [21/200], Loss: 0.0820\n",
            "Epoch [22/200], Loss: 0.0811\n",
            "Epoch [23/200], Loss: 0.0776\n",
            "Epoch [24/200], Loss: 0.0802\n",
            "Epoch [25/200], Loss: 0.0738\n",
            "Epoch [26/200], Loss: 0.0698\n",
            "Epoch [27/200], Loss: 0.0746\n",
            "Epoch [28/200], Loss: 0.0597\n",
            "Epoch [29/200], Loss: 0.0724\n",
            "Epoch [30/200], Loss: 0.0627\n",
            "Epoch [31/200], Loss: 0.0581\n",
            "Epoch [32/200], Loss: 0.0683\n",
            "Epoch [33/200], Loss: 0.0623\n",
            "Epoch [34/200], Loss: 0.0610\n",
            "Epoch [35/200], Loss: 0.0556\n",
            "Epoch [36/200], Loss: 0.0612\n",
            "Epoch [37/200], Loss: 0.0577\n",
            "Epoch [38/200], Loss: 0.0580\n",
            "Epoch [39/200], Loss: 0.0562\n",
            "Epoch [40/200], Loss: 0.0539\n",
            "Epoch [41/200], Loss: 0.0509\n",
            "Epoch [42/200], Loss: 0.0507\n",
            "Epoch [43/200], Loss: 0.0545\n",
            "Epoch [44/200], Loss: 0.0539\n",
            "Epoch [45/200], Loss: 0.0506\n",
            "Epoch [46/200], Loss: 0.0509\n",
            "Epoch [47/200], Loss: 0.0495\n",
            "Epoch [48/200], Loss: 0.0467\n",
            "Epoch [49/200], Loss: 0.0495\n",
            "Epoch [50/200], Loss: 0.0465\n",
            "Epoch [51/200], Loss: 0.0479\n",
            "Epoch [52/200], Loss: 0.0424\n",
            "Epoch [53/200], Loss: 0.0519\n",
            "Epoch [54/200], Loss: 0.0420\n",
            "Epoch [55/200], Loss: 0.0442\n",
            "Epoch [56/200], Loss: 0.0498\n",
            "Epoch [57/200], Loss: 0.0437\n",
            "Epoch [58/200], Loss: 0.0432\n",
            "Epoch [59/200], Loss: 0.0507\n",
            "Epoch [60/200], Loss: 0.0459\n",
            "Epoch [61/200], Loss: 0.0445\n",
            "Epoch [62/200], Loss: 0.0345\n",
            "Epoch [63/200], Loss: 0.0474\n",
            "Epoch [64/200], Loss: 0.0427\n",
            "Epoch [65/200], Loss: 0.0465\n",
            "Epoch [66/200], Loss: 0.0427\n",
            "Epoch [67/200], Loss: 0.0417\n",
            "Epoch [68/200], Loss: 0.0466\n",
            "Epoch [69/200], Loss: 0.0435\n",
            "Epoch [70/200], Loss: 0.0400\n",
            "Epoch [71/200], Loss: 0.0433\n",
            "Epoch [72/200], Loss: 0.0390\n",
            "Epoch [73/200], Loss: 0.0450\n",
            "Epoch [74/200], Loss: 0.0446\n",
            "Epoch [75/200], Loss: 0.0356\n",
            "Epoch [76/200], Loss: 0.0406\n",
            "Epoch [77/200], Loss: 0.0458\n",
            "Epoch [78/200], Loss: 0.0323\n",
            "Epoch [79/200], Loss: 0.0476\n",
            "Epoch [80/200], Loss: 0.0427\n",
            "Epoch [81/200], Loss: 0.0355\n",
            "Epoch [82/200], Loss: 0.0478\n",
            "Epoch [83/200], Loss: 0.0379\n",
            "Epoch [84/200], Loss: 0.0402\n",
            "Epoch [85/200], Loss: 0.0361\n",
            "Epoch [86/200], Loss: 0.0393\n",
            "Epoch [87/200], Loss: 0.0357\n",
            "Epoch [88/200], Loss: 0.0394\n",
            "Epoch [89/200], Loss: 0.0447\n",
            "Epoch [90/200], Loss: 0.0385\n",
            "Epoch [91/200], Loss: 0.0392\n",
            "Epoch [92/200], Loss: 0.0403\n",
            "Epoch [93/200], Loss: 0.0390\n",
            "Epoch [94/200], Loss: 0.0333\n",
            "Epoch [95/200], Loss: 0.0394\n",
            "Epoch [96/200], Loss: 0.0406\n",
            "Epoch [97/200], Loss: 0.0359\n",
            "Epoch [98/200], Loss: 0.0402\n",
            "Epoch [99/200], Loss: 0.0351\n",
            "Epoch [100/200], Loss: 0.0343\n",
            "Epoch [101/200], Loss: 0.0360\n",
            "Epoch [102/200], Loss: 0.0372\n",
            "Epoch [103/200], Loss: 0.0346\n",
            "Epoch [104/200], Loss: 0.0350\n",
            "Epoch [105/200], Loss: 0.0378\n",
            "Epoch [106/200], Loss: 0.0348\n",
            "Epoch [107/200], Loss: 0.0403\n",
            "Epoch [108/200], Loss: 0.0331\n",
            "Epoch [109/200], Loss: 0.0354\n",
            "Epoch [110/200], Loss: 0.0386\n",
            "Epoch [111/200], Loss: 0.0384\n",
            "Epoch [112/200], Loss: 0.0354\n",
            "Epoch [113/200], Loss: 0.0324\n",
            "Epoch [114/200], Loss: 0.0414\n",
            "Epoch [115/200], Loss: 0.0351\n",
            "Epoch [116/200], Loss: 0.0375\n",
            "Epoch [117/200], Loss: 0.0349\n",
            "Epoch [118/200], Loss: 0.0390\n",
            "Epoch [119/200], Loss: 0.0393\n",
            "Epoch [120/200], Loss: 0.0432\n",
            "Epoch [121/200], Loss: 0.0353\n",
            "Epoch [122/200], Loss: 0.0378\n",
            "Epoch [123/200], Loss: 0.0352\n",
            "Epoch [124/200], Loss: 0.0388\n",
            "Epoch [125/200], Loss: 0.0387\n",
            "Epoch [126/200], Loss: 0.0357\n",
            "Epoch [127/200], Loss: 0.0324\n",
            "Epoch [128/200], Loss: 0.0362\n",
            "Epoch [129/200], Loss: 0.0368\n",
            "Epoch [130/200], Loss: 0.0374\n",
            "Epoch [131/200], Loss: 0.0342\n",
            "Epoch [132/200], Loss: 0.0362\n",
            "Epoch [133/200], Loss: 0.0360\n",
            "Epoch [134/200], Loss: 0.0435\n",
            "Epoch [135/200], Loss: 0.0319\n",
            "Epoch [136/200], Loss: 0.0387\n",
            "Epoch [137/200], Loss: 0.0360\n",
            "Epoch [138/200], Loss: 0.0397\n",
            "Epoch [139/200], Loss: 0.0329\n",
            "Epoch [140/200], Loss: 0.0396\n",
            "Epoch [141/200], Loss: 0.0406\n",
            "Epoch [142/200], Loss: 0.0364\n",
            "Epoch [143/200], Loss: 0.0300\n",
            "Epoch [144/200], Loss: 0.0398\n",
            "Epoch [145/200], Loss: 0.0351\n",
            "Epoch [146/200], Loss: 0.0316\n",
            "Epoch [147/200], Loss: 0.0448\n",
            "Epoch [148/200], Loss: 0.0312\n",
            "Epoch [149/200], Loss: 0.0376\n",
            "Epoch [150/200], Loss: 0.0328\n",
            "Epoch [151/200], Loss: 0.0361\n",
            "Epoch [152/200], Loss: 0.0389\n",
            "Epoch [153/200], Loss: 0.0371\n",
            "Epoch [154/200], Loss: 0.0414\n",
            "Epoch [155/200], Loss: 0.0356\n",
            "Epoch [156/200], Loss: 0.0390\n",
            "Epoch [157/200], Loss: 0.0380\n",
            "Epoch [158/200], Loss: 0.0397\n",
            "Epoch [159/200], Loss: 0.0301\n",
            "Epoch [160/200], Loss: 0.0385\n",
            "Epoch [161/200], Loss: 0.0368\n",
            "Epoch [162/200], Loss: 0.0403\n",
            "Epoch [163/200], Loss: 0.0345\n",
            "Epoch [164/200], Loss: 0.0426\n",
            "Epoch [165/200], Loss: 0.0370\n",
            "Epoch [166/200], Loss: 0.0404\n",
            "Epoch [167/200], Loss: 0.0371\n",
            "Epoch [168/200], Loss: 0.0375\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "# Define the CNN model\n",
        "class BasicCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BasicCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BasicCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the model\n",
        "def train_model(model, trainloader, criterion, optimizer, epochs=200):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(trainloader):.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Training completed in: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Run training\n",
        "train_model(model, trainloader, criterion, optimizer, epochs=200)\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "# Run evaluation\n",
        "evaluate_model(model, testloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn # Import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "# Define device here to make it accessible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the CNN model\n",
        "class ExtendedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExtendedCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Training the model\n",
        "def train_model(model, trainloader, criterion, optimizer, epochs=200):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(trainloader):.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Training completed in: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[0].to"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL8BtfThQmgQ",
        "outputId": "98dd1067-94f5-451d-f377-4f2f3b487f6f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 35.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet10(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet10, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(64, 64, 3, stride=1)\n",
        "        self.layer2 = self._make_layer(64, 128, 3, stride=2)\n",
        "        # Changed the input size of the fully connected layer\n",
        "        self.fc = nn.Linear(128 * 4 * 4, num_classes)\n",
        "\n",
        "    def _make_layer(self, in_channels, out_channels, blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(BasicBlock(in_channels, out_channels, stride))\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(BasicBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Training the model\n",
        "def train_model(model, trainloader, criterion, optimizer, epochs=200):\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            optimizer.zero_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW-swpufRqt8",
        "outputId": "89b4182d-f7d5-4c38-f856-f38aa997d3c1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    }
  ]
}