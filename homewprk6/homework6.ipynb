{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd6YUpf7Zfya",
        "outputId": "edf20344-29f8-40b8-8625-3c787beba0b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/1000 - Train Loss: 0.0240, Validation Loss: 0.0229\n",
            "Epoch 200/1000 - Train Loss: 0.0175, Validation Loss: 0.0174\n",
            "Epoch 300/1000 - Train Loss: 0.0152, Validation Loss: 0.0154\n",
            "Epoch 400/1000 - Train Loss: 0.0139, Validation Loss: 0.0143\n",
            "Epoch 500/1000 - Train Loss: 0.0129, Validation Loss: 0.0137\n",
            "Epoch 600/1000 - Train Loss: 0.0121, Validation Loss: 0.0131\n",
            "Epoch 700/1000 - Train Loss: 0.0113, Validation Loss: 0.0126\n",
            "Epoch 800/1000 - Train Loss: 0.0105, Validation Loss: 0.0120\n",
            "Epoch 900/1000 - Train Loss: 0.0096, Validation Loss: 0.0113\n",
            "Epoch 1000/1000 - Train Loss: 0.0085, Validation Loss: 0.0104\n",
            "Final Train Loss: 0.008531803265213966\n",
            "Final Validation Loss: 0.01039207261055708\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Generate or load your dataset (replace make_regression with your actual housing data)\n",
        "X, y = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
        "\n",
        "# Data preprocessing\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler_X = StandardScaler()\n",
        "scaler_y = StandardScaler()\n",
        "\n",
        "X_train = scaler_X.fit_transform(X_train)\n",
        "X_val = scaler_X.transform(X_val)\n",
        "y_train = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
        "y_val = scaler_y.transform(y_val.reshape(-1, 1))\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Define the model\n",
        "class HousingSingleLayerModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Train function\n",
        "def train_single_layer_housing_model(X_train, y_train, X_val, y_val, learning_rate, epochs):\n",
        "    input_dim = X_train.shape[1]\n",
        "    hidden_dim = 8\n",
        "    model = HousingSingleLayerModel(input_dim, hidden_dim)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(X_train)\n",
        "        train_loss = loss_fn(predictions, y_train)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_predictions = model(X_val)\n",
        "            val_loss = loss_fn(val_predictions, y_val).item()\n",
        "\n",
        "        if (epoch + 1) % 100 == 0:\n",
        "            train_losses.append(train_loss.item())\n",
        "            val_losses.append(val_loss)\n",
        "            print(f\"Epoch {epoch + 1}/{epochs} - Train Loss: {train_loss.item():.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    print(\"Final Train Loss:\", train_losses[-1])\n",
        "    print(\"Final Validation Loss:\", val_losses[-1])\n",
        "    return model, train_losses, val_losses\n",
        "\n",
        "# Train the model\n",
        "single_layer_model, train_losses_1a, val_losses_1a = train_single_layer_housing_model(\n",
        "    X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, learning_rate=0.05, epochs=1000\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HousingMultiLayerModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dims[0])\n",
        "        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
        "        self.fc3 = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
        "        self.fc4 = nn.Linear(hidden_dims[2], 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(self.relu(self.fc2(x)))\n",
        "        x = self.dropout(self.relu(self.fc3(x)))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "def train_multi_layer_housing_model(X_train, y_train, X_val, y_val, learning_rate, epochs):\n",
        "    input_dim = X_train.shape[1]\n",
        "    hidden_dims = [64, 32, 16]\n",
        "    model = HousingMultiLayerModel(input_dim, hidden_dims)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(X_train)\n",
        "        train_loss = loss_fn(predictions, y_train)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_predictions = model(X_val)\n",
        "            val_loss = loss_fn(val_predictions, y_val).item()\n",
        "\n",
        "        if (epoch + 1) % 100 == 0:\n",
        "            train_losses.append(train_loss.item())\n",
        "            val_losses.append(val_loss)\n",
        "            print(f\"Epoch {epoch + 1}/{epochs} - Train Loss: {train_loss.item():.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    print(\"Final Train Loss:\", train_losses[-1])\n",
        "    print(\"Final Validation Loss:\", val_losses[-1])\n",
        "    return model, train_losses, val_losses\n",
        "\n",
        "# Train the model\n",
        "multi_layer_model, train_losses_1b, val_losses_1b = train_multi_layer_housing_model(\n",
        "    X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, learning_rate=0.001, epochs=1000\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkXF8DYKacU2",
        "outputId": "a91700fd-87da-4a23-ed44-670b9be767c0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/1000 - Train Loss: 0.0975, Validation Loss: 0.0274\n",
            "Epoch 200/1000 - Train Loss: 0.0584, Validation Loss: 0.0096\n",
            "Epoch 300/1000 - Train Loss: 0.0475, Validation Loss: 0.0063\n",
            "Epoch 400/1000 - Train Loss: 0.0480, Validation Loss: 0.0055\n",
            "Epoch 500/1000 - Train Loss: 0.0522, Validation Loss: 0.0064\n",
            "Epoch 600/1000 - Train Loss: 0.0445, Validation Loss: 0.0049\n",
            "Epoch 700/1000 - Train Loss: 0.0482, Validation Loss: 0.0044\n",
            "Epoch 800/1000 - Train Loss: 0.0465, Validation Loss: 0.0061\n",
            "Epoch 900/1000 - Train Loss: 0.0506, Validation Loss: 0.0045\n",
            "Epoch 1000/1000 - Train Loss: 0.0376, Validation Loss: 0.0063\n",
            "Final Train Loss: 0.037569064646959305\n",
            "Final Validation Loss: 0.006254489999264479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the cancer dataset\n",
        "cancer_data = load_breast_cancer()\n",
        "X = cancer_data.data\n",
        "y = cancer_data.target\n",
        "\n",
        "# Split and preprocess\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler_X = StandardScaler()\n",
        "X_train = scaler_X.fit_transform(X_train)\n",
        "X_val = scaler_X.transform(X_val)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Define the single-hidden-layer model\n",
        "class CancerSingleLayerModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Train function\n",
        "def train_single_layer_cancer_model(X_train, y_train, X_val, y_val, learning_rate, epochs):\n",
        "    input_dim = X_train.shape[1]\n",
        "    hidden_dim = 32\n",
        "    model = CancerSingleLayerModel(input_dim, hidden_dim)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    loss_fn = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(X_train)\n",
        "        train_loss = loss_fn(predictions, y_train)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_predictions = model(X_val)\n",
        "            val_loss = loss_fn(val_predictions, y_val).item()\n",
        "\n",
        "        if (epoch + 1) % 100 == 0:\n",
        "            train_losses.append(train_loss.item())\n",
        "            val_losses.append(val_loss)\n",
        "            print(f\"Epoch {epoch + 1}/{epochs} - Train Loss: {train_loss.item():.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    print(\"Final Train Loss:\", train_losses[-1])\n",
        "    print(\"Final Validation Loss:\", val_losses[-1])\n",
        "    return model, train_losses, val_losses\n",
        "\n",
        "# Train the model\n",
        "single_layer_cancer_model, train_losses_2a, val_losses_2a = train_single_layer_cancer_model(\n",
        "    X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, learning_rate=0.001, epochs=1000\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7VM3iY-aeVH",
        "outputId": "9a19ce13-a97e-4003-e1a9-226ad2e325a4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/1000 - Train Loss: 0.1647, Validation Loss: 0.1503\n",
            "Epoch 200/1000 - Train Loss: 0.0857, Validation Loss: 0.0794\n",
            "Epoch 300/1000 - Train Loss: 0.0616, Validation Loss: 0.0651\n",
            "Epoch 400/1000 - Train Loss: 0.0495, Validation Loss: 0.0615\n",
            "Epoch 500/1000 - Train Loss: 0.0412, Validation Loss: 0.0603\n",
            "Epoch 600/1000 - Train Loss: 0.0347, Validation Loss: 0.0606\n",
            "Epoch 700/1000 - Train Loss: 0.0290, Validation Loss: 0.0621\n",
            "Epoch 800/1000 - Train Loss: 0.0239, Validation Loss: 0.0642\n",
            "Epoch 900/1000 - Train Loss: 0.0195, Validation Loss: 0.0667\n",
            "Epoch 1000/1000 - Train Loss: 0.0159, Validation Loss: 0.0697\n",
            "Final Train Loss: 0.01588340476155281\n",
            "Final Validation Loss: 0.06972919404506683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CancerMultiLayerModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dims[0])\n",
        "        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
        "        self.fc3 = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
        "        self.fc4 = nn.Linear(hidden_dims[2], 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "# Train function\n",
        "def train_multi_layer_cancer_model(X_train, y_train, X_val, y_val, learning_rate, epochs):\n",
        "    input_dim = X_train.shape[1]\n",
        "    hidden_dims = [64, 32, 16]\n",
        "    model = CancerMultiLayerModel(input_dim, hidden_dims)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    loss_fn = nn.BCELoss()\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(X_train)\n",
        "        train_loss = loss_fn(predictions, y_train)\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_predictions = model(X_val)\n",
        "            val_loss = loss_fn(val_predictions, y_val).item()\n",
        "\n",
        "        if (epoch + 1) % 100 == 0:\n",
        "            train_losses.append(train_loss.item())\n",
        "            val_losses.append(val_loss)\n",
        "            print(f\"Epoch {epoch + 1}/{epochs} - Train Loss: {train_loss.item():.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    print(\"Final Train Loss:\", train_losses[-1])\n",
        "    print(\"Final Validation Loss:\", val_losses[-1])\n",
        "    return model, train_losses, val_losses\n",
        "\n",
        "# Train the model\n",
        "multi_layer_cancer_model, train_losses_2b, val_losses_2b = train_multi_layer_cancer_model(\n",
        "    X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, learning_rate=0.001, epochs=1000\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TcKQ3hmalTf",
        "outputId": "c026ac2e-1304-4a03-a278-d7baa305d9c9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/1000 - Train Loss: 0.0477, Validation Loss: 0.0601\n",
            "Epoch 200/1000 - Train Loss: 0.0136, Validation Loss: 0.0695\n",
            "Epoch 300/1000 - Train Loss: 0.0016, Validation Loss: 0.0906\n",
            "Epoch 400/1000 - Train Loss: 0.0005, Validation Loss: 0.1075\n",
            "Epoch 500/1000 - Train Loss: 0.0003, Validation Loss: 0.1200\n",
            "Epoch 600/1000 - Train Loss: 0.0002, Validation Loss: 0.1297\n",
            "Epoch 700/1000 - Train Loss: 0.0001, Validation Loss: 0.1372\n",
            "Epoch 800/1000 - Train Loss: 0.0001, Validation Loss: 0.1436\n",
            "Epoch 900/1000 - Train Loss: 0.0001, Validation Loss: 0.1493\n",
            "Epoch 1000/1000 - Train Loss: 0.0000, Validation Loss: 0.1543\n",
            "Final Train Loss: 4.543393515632488e-05\n",
            "Final Validation Loss: 0.1542828530073166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define the model with one hidden layer of 256 nodes\n",
        "class CIFARSingleLayerModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten input\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Train function\n",
        "def train_single_layer_cifar_model(train_loader, test_loader, learning_rate, epochs):\n",
        "    input_dim = 32 * 32 * 3  # CIFAR-10 images are 32x32x3\n",
        "    hidden_dim = 256\n",
        "    output_dim = 10  # 10 classes\n",
        "    model = CIFARSingleLayerModel(input_dim, hidden_dim, output_dim)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses, test_accuracies = [], []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training step\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_losses.append(running_loss / len(train_loader))\n",
        "        test_accuracies.append(100 * correct / total)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_losses[-1]:.4f}, Accuracy: {test_accuracies[-1]:.2f}%\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    return model, train_losses, test_accuracies, training_time\n",
        "\n",
        "# Train the model\n",
        "single_layer_model, train_losses_3a, test_accuracies_3a, training_time_3a = train_single_layer_cifar_model(\n",
        "    train_loader, test_loader, learning_rate=0.01, epochs=100\n",
        ")\n",
        "\n",
        "# Display results\n",
        "print(\"Problem 3a Results (Single Hidden Layer):\")\n",
        "print(\"Training Time:\", training_time_3a, \"seconds\")\n",
        "print(\"Train Losses (last epoch):\", train_losses_3a[-1])\n",
        "print(\"Test Accuracy:\", test_accuracies_3a[-1], \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Dw7noFs5ayJZ",
        "outputId": "0fef4a88-336b-4e97-c894-4d421c9974c4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:15<00:00, 10.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Epoch 1/100, Loss: 1.8846, Accuracy: 40.32%\n",
            "Epoch 2/100, Loss: 1.6635, Accuracy: 43.82%\n",
            "Epoch 3/100, Loss: 1.5794, Accuracy: 45.95%\n",
            "Epoch 4/100, Loss: 1.5239, Accuracy: 46.78%\n",
            "Epoch 5/100, Loss: 1.4802, Accuracy: 48.32%\n",
            "Epoch 6/100, Loss: 1.4406, Accuracy: 48.96%\n",
            "Epoch 7/100, Loss: 1.4071, Accuracy: 49.48%\n",
            "Epoch 8/100, Loss: 1.3752, Accuracy: 49.92%\n",
            "Epoch 9/100, Loss: 1.3459, Accuracy: 50.40%\n",
            "Epoch 10/100, Loss: 1.3188, Accuracy: 51.25%\n",
            "Epoch 11/100, Loss: 1.2936, Accuracy: 51.00%\n",
            "Epoch 12/100, Loss: 1.2684, Accuracy: 51.75%\n",
            "Epoch 13/100, Loss: 1.2459, Accuracy: 52.10%\n",
            "Epoch 14/100, Loss: 1.2237, Accuracy: 52.32%\n",
            "Epoch 15/100, Loss: 1.2033, Accuracy: 53.08%\n",
            "Epoch 16/100, Loss: 1.1840, Accuracy: 51.88%\n",
            "Epoch 17/100, Loss: 1.1636, Accuracy: 52.56%\n",
            "Epoch 18/100, Loss: 1.1452, Accuracy: 52.65%\n",
            "Epoch 19/100, Loss: 1.1279, Accuracy: 52.96%\n",
            "Epoch 20/100, Loss: 1.1095, Accuracy: 52.47%\n",
            "Epoch 21/100, Loss: 1.0912, Accuracy: 51.80%\n",
            "Epoch 22/100, Loss: 1.0742, Accuracy: 53.18%\n",
            "Epoch 23/100, Loss: 1.0574, Accuracy: 53.05%\n",
            "Epoch 24/100, Loss: 1.0416, Accuracy: 52.91%\n",
            "Epoch 25/100, Loss: 1.0251, Accuracy: 53.27%\n",
            "Epoch 26/100, Loss: 1.0094, Accuracy: 53.42%\n",
            "Epoch 27/100, Loss: 0.9932, Accuracy: 53.71%\n",
            "Epoch 28/100, Loss: 0.9779, Accuracy: 53.48%\n",
            "Epoch 29/100, Loss: 0.9623, Accuracy: 52.65%\n",
            "Epoch 30/100, Loss: 0.9479, Accuracy: 53.19%\n",
            "Epoch 31/100, Loss: 0.9322, Accuracy: 53.31%\n",
            "Epoch 32/100, Loss: 0.9174, Accuracy: 52.66%\n",
            "Epoch 33/100, Loss: 0.9024, Accuracy: 53.59%\n",
            "Epoch 34/100, Loss: 0.8899, Accuracy: 53.13%\n",
            "Epoch 35/100, Loss: 0.8748, Accuracy: 53.58%\n",
            "Epoch 36/100, Loss: 0.8607, Accuracy: 53.43%\n",
            "Epoch 37/100, Loss: 0.8467, Accuracy: 53.04%\n",
            "Epoch 38/100, Loss: 0.8326, Accuracy: 52.97%\n",
            "Epoch 39/100, Loss: 0.8200, Accuracy: 53.24%\n",
            "Epoch 40/100, Loss: 0.8075, Accuracy: 52.86%\n",
            "Epoch 41/100, Loss: 0.7925, Accuracy: 53.07%\n",
            "Epoch 42/100, Loss: 0.7812, Accuracy: 53.19%\n",
            "Epoch 43/100, Loss: 0.7668, Accuracy: 52.93%\n",
            "Epoch 44/100, Loss: 0.7544, Accuracy: 52.12%\n",
            "Epoch 45/100, Loss: 0.7431, Accuracy: 52.61%\n",
            "Epoch 46/100, Loss: 0.7314, Accuracy: 52.89%\n",
            "Epoch 47/100, Loss: 0.7158, Accuracy: 51.69%\n",
            "Epoch 48/100, Loss: 0.7055, Accuracy: 51.56%\n",
            "Epoch 49/100, Loss: 0.6931, Accuracy: 52.95%\n",
            "Epoch 50/100, Loss: 0.6832, Accuracy: 51.60%\n",
            "Epoch 51/100, Loss: 0.6679, Accuracy: 51.10%\n",
            "Epoch 52/100, Loss: 0.6586, Accuracy: 52.78%\n",
            "Epoch 53/100, Loss: 0.6471, Accuracy: 52.77%\n",
            "Epoch 54/100, Loss: 0.6358, Accuracy: 52.29%\n",
            "Epoch 55/100, Loss: 0.6236, Accuracy: 52.35%\n",
            "Epoch 56/100, Loss: 0.6134, Accuracy: 53.21%\n",
            "Epoch 57/100, Loss: 0.6027, Accuracy: 51.03%\n",
            "Epoch 58/100, Loss: 0.5928, Accuracy: 50.28%\n",
            "Epoch 59/100, Loss: 0.5812, Accuracy: 52.22%\n",
            "Epoch 60/100, Loss: 0.5720, Accuracy: 52.11%\n",
            "Epoch 61/100, Loss: 0.5601, Accuracy: 52.02%\n",
            "Epoch 62/100, Loss: 0.5519, Accuracy: 52.31%\n",
            "Epoch 63/100, Loss: 0.5416, Accuracy: 52.68%\n",
            "Epoch 64/100, Loss: 0.5309, Accuracy: 51.80%\n",
            "Epoch 65/100, Loss: 0.5216, Accuracy: 50.98%\n",
            "Epoch 66/100, Loss: 0.5122, Accuracy: 51.01%\n",
            "Epoch 67/100, Loss: 0.5032, Accuracy: 51.49%\n",
            "Epoch 68/100, Loss: 0.4938, Accuracy: 51.94%\n",
            "Epoch 69/100, Loss: 0.4848, Accuracy: 51.62%\n",
            "Epoch 70/100, Loss: 0.4751, Accuracy: 52.16%\n",
            "Epoch 71/100, Loss: 0.4673, Accuracy: 51.03%\n",
            "Epoch 72/100, Loss: 0.4590, Accuracy: 49.76%\n",
            "Epoch 73/100, Loss: 0.4504, Accuracy: 51.44%\n",
            "Epoch 74/100, Loss: 0.4409, Accuracy: 51.91%\n",
            "Epoch 75/100, Loss: 0.4322, Accuracy: 50.60%\n",
            "Epoch 76/100, Loss: 0.4242, Accuracy: 52.07%\n",
            "Epoch 77/100, Loss: 0.4165, Accuracy: 52.05%\n",
            "Epoch 78/100, Loss: 0.4074, Accuracy: 50.89%\n",
            "Epoch 79/100, Loss: 0.3998, Accuracy: 51.58%\n",
            "Epoch 80/100, Loss: 0.3933, Accuracy: 49.81%\n",
            "Epoch 81/100, Loss: 0.3850, Accuracy: 51.60%\n",
            "Epoch 82/100, Loss: 0.3756, Accuracy: 50.94%\n",
            "Epoch 83/100, Loss: 0.3709, Accuracy: 51.35%\n",
            "Epoch 84/100, Loss: 0.3636, Accuracy: 51.15%\n",
            "Epoch 85/100, Loss: 0.3550, Accuracy: 51.10%\n",
            "Epoch 86/100, Loss: 0.3487, Accuracy: 50.05%\n",
            "Epoch 87/100, Loss: 0.3422, Accuracy: 50.79%\n",
            "Epoch 88/100, Loss: 0.3348, Accuracy: 50.07%\n",
            "Epoch 89/100, Loss: 0.3270, Accuracy: 51.70%\n",
            "Epoch 90/100, Loss: 0.3227, Accuracy: 47.79%\n",
            "Epoch 91/100, Loss: 0.3173, Accuracy: 48.67%\n",
            "Epoch 92/100, Loss: 0.3090, Accuracy: 49.81%\n",
            "Epoch 93/100, Loss: 0.3017, Accuracy: 50.04%\n",
            "Epoch 94/100, Loss: 0.2970, Accuracy: 51.47%\n",
            "Epoch 95/100, Loss: 0.2901, Accuracy: 50.37%\n",
            "Epoch 96/100, Loss: 0.2838, Accuracy: 51.31%\n",
            "Epoch 97/100, Loss: 0.2775, Accuracy: 51.43%\n",
            "Epoch 98/100, Loss: 0.2717, Accuracy: 51.28%\n",
            "Epoch 99/100, Loss: 0.2663, Accuracy: 51.08%\n",
            "Epoch 100/100, Loss: 0.2606, Accuracy: 50.72%\n",
            "Problem 3a Results (Single Hidden Layer):\n",
            "Training Time: 1804.400067806244 seconds\n",
            "Train Losses (last epoch): 0.2606372979405286\n",
            "Test Accuracy: 50.72 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model with three hidden layers\n",
        "class CIFARMultiLayerModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dims[0])\n",
        "        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
        "        self.fc3 = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
        "        self.fc4 = nn.Linear(hidden_dims[2], output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # Flatten input\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Train function for multi-layer network\n",
        "def train_multi_layer_cifar_model(train_loader, test_loader, learning_rate, epochs):\n",
        "    input_dim = 32 * 32 * 3\n",
        "    hidden_dims = [512, 256, 128]  # Three hidden layers\n",
        "    output_dim = 10\n",
        "    model = CIFARMultiLayerModel(input_dim, hidden_dims, output_dim)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses, test_accuracies = [], []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training step\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_losses.append(running_loss / len(train_loader))\n",
        "        test_accuracies.append(100 * correct / total)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_losses[-1]:.4f}, Accuracy: {test_accuracies[-1]:.2f}%\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    return model, train_losses, test_accuracies, training_time\n",
        "\n",
        "# Train the model\n",
        "multi_layer_model, train_losses_3b, test_accuracies_3b, training_time_3b = train_multi_layer_cifar_model(\n",
        "    train_loader, test_loader, learning_rate=0.01, epochs=100\n",
        ")\n",
        "\n",
        "# Display results\n",
        "print(\"Problem 3b Results (Three Hidden Layers):\")\n",
        "print(\"Training Time:\", training_time_3b, \"seconds\")\n",
        "print(\"Train Losses (last epoch):\", train_losses_3b[-1])\n",
        "print(\"Test Accuracy:\", test_accuracies_3b[-1], \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "trgPGAOdc6Ls",
        "outputId": "eef15a77-bebb-4f49-d2ac-ee11f4f14336"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 2.1856, Accuracy: 29.34%\n",
            "Epoch 2/100, Loss: 1.8995, Accuracy: 36.61%\n",
            "Epoch 3/100, Loss: 1.7320, Accuracy: 40.86%\n",
            "Epoch 4/100, Loss: 1.6304, Accuracy: 43.67%\n",
            "Epoch 5/100, Loss: 1.5553, Accuracy: 46.28%\n",
            "Epoch 6/100, Loss: 1.4884, Accuracy: 47.91%\n",
            "Epoch 7/100, Loss: 1.4295, Accuracy: 48.12%\n",
            "Epoch 8/100, Loss: 1.3773, Accuracy: 49.80%\n",
            "Epoch 9/100, Loss: 1.3295, Accuracy: 50.33%\n",
            "Epoch 10/100, Loss: 1.2848, Accuracy: 51.81%\n",
            "Epoch 11/100, Loss: 1.2439, Accuracy: 51.54%\n",
            "Epoch 12/100, Loss: 1.2039, Accuracy: 51.77%\n",
            "Epoch 13/100, Loss: 1.1677, Accuracy: 52.24%\n",
            "Epoch 14/100, Loss: 1.1329, Accuracy: 48.65%\n",
            "Epoch 15/100, Loss: 1.0998, Accuracy: 51.94%\n",
            "Epoch 16/100, Loss: 1.0651, Accuracy: 51.57%\n",
            "Epoch 17/100, Loss: 1.0324, Accuracy: 52.92%\n",
            "Epoch 18/100, Loss: 1.0002, Accuracy: 52.51%\n",
            "Epoch 19/100, Loss: 0.9679, Accuracy: 50.49%\n",
            "Epoch 20/100, Loss: 0.9386, Accuracy: 50.97%\n",
            "Epoch 21/100, Loss: 0.9076, Accuracy: 52.44%\n",
            "Epoch 22/100, Loss: 0.8751, Accuracy: 53.82%\n",
            "Epoch 23/100, Loss: 0.8467, Accuracy: 50.12%\n",
            "Epoch 24/100, Loss: 0.8166, Accuracy: 51.99%\n",
            "Epoch 25/100, Loss: 0.7880, Accuracy: 51.71%\n",
            "Epoch 26/100, Loss: 0.7596, Accuracy: 50.32%\n",
            "Epoch 27/100, Loss: 0.7308, Accuracy: 52.69%\n",
            "Epoch 28/100, Loss: 0.7058, Accuracy: 52.33%\n",
            "Epoch 29/100, Loss: 0.6765, Accuracy: 47.74%\n",
            "Epoch 30/100, Loss: 0.6476, Accuracy: 49.56%\n",
            "Epoch 31/100, Loss: 0.6266, Accuracy: 53.46%\n",
            "Epoch 32/100, Loss: 0.5942, Accuracy: 47.94%\n",
            "Epoch 33/100, Loss: 0.5732, Accuracy: 47.40%\n",
            "Epoch 34/100, Loss: 0.5437, Accuracy: 44.98%\n",
            "Epoch 35/100, Loss: 0.5240, Accuracy: 48.46%\n",
            "Epoch 36/100, Loss: 0.5023, Accuracy: 50.71%\n",
            "Epoch 37/100, Loss: 0.4727, Accuracy: 45.92%\n",
            "Epoch 38/100, Loss: 0.4592, Accuracy: 52.19%\n",
            "Epoch 39/100, Loss: 0.4266, Accuracy: 49.34%\n",
            "Epoch 40/100, Loss: 0.4094, Accuracy: 49.34%\n",
            "Epoch 41/100, Loss: 0.3903, Accuracy: 51.16%\n",
            "Epoch 42/100, Loss: 0.3699, Accuracy: 53.27%\n",
            "Epoch 43/100, Loss: 0.3438, Accuracy: 53.54%\n",
            "Epoch 44/100, Loss: 0.3367, Accuracy: 50.88%\n",
            "Epoch 45/100, Loss: 0.3208, Accuracy: 51.36%\n",
            "Epoch 46/100, Loss: 0.2939, Accuracy: 51.81%\n",
            "Epoch 47/100, Loss: 0.2807, Accuracy: 51.75%\n",
            "Epoch 48/100, Loss: 0.2688, Accuracy: 48.98%\n",
            "Epoch 49/100, Loss: 0.2489, Accuracy: 52.09%\n",
            "Epoch 50/100, Loss: 0.2391, Accuracy: 53.21%\n",
            "Epoch 51/100, Loss: 0.2117, Accuracy: 51.85%\n",
            "Epoch 52/100, Loss: 0.2090, Accuracy: 53.22%\n",
            "Epoch 53/100, Loss: 0.2146, Accuracy: 51.24%\n",
            "Epoch 54/100, Loss: 0.1924, Accuracy: 46.02%\n",
            "Epoch 55/100, Loss: 0.1863, Accuracy: 51.41%\n",
            "Epoch 56/100, Loss: 0.1924, Accuracy: 47.01%\n",
            "Epoch 57/100, Loss: 0.1564, Accuracy: 51.06%\n",
            "Epoch 58/100, Loss: 0.1360, Accuracy: 51.98%\n",
            "Epoch 59/100, Loss: 0.1248, Accuracy: 49.86%\n",
            "Epoch 60/100, Loss: 0.1303, Accuracy: 52.50%\n",
            "Epoch 61/100, Loss: 0.1207, Accuracy: 48.21%\n",
            "Epoch 62/100, Loss: 0.1216, Accuracy: 53.78%\n",
            "Epoch 63/100, Loss: 0.1129, Accuracy: 41.85%\n",
            "Epoch 64/100, Loss: 0.1579, Accuracy: 48.51%\n",
            "Epoch 65/100, Loss: 0.0713, Accuracy: 53.17%\n",
            "Epoch 66/100, Loss: 0.0738, Accuracy: 52.66%\n",
            "Epoch 67/100, Loss: 0.0688, Accuracy: 45.89%\n",
            "Epoch 68/100, Loss: 0.1186, Accuracy: 53.64%\n",
            "Epoch 69/100, Loss: 0.1106, Accuracy: 47.95%\n",
            "Epoch 70/100, Loss: 0.1052, Accuracy: 51.31%\n",
            "Epoch 71/100, Loss: 0.0622, Accuracy: 53.50%\n",
            "Epoch 72/100, Loss: 0.0513, Accuracy: 51.24%\n",
            "Epoch 73/100, Loss: 0.0514, Accuracy: 53.08%\n",
            "Epoch 74/100, Loss: 0.0240, Accuracy: 53.94%\n",
            "Epoch 75/100, Loss: 0.0173, Accuracy: 54.09%\n",
            "Epoch 76/100, Loss: 0.0189, Accuracy: 52.88%\n",
            "Epoch 77/100, Loss: 0.0143, Accuracy: 54.03%\n",
            "Epoch 78/100, Loss: 0.0100, Accuracy: 52.82%\n",
            "Epoch 79/100, Loss: 0.0098, Accuracy: 54.08%\n",
            "Epoch 80/100, Loss: 0.0071, Accuracy: 54.22%\n",
            "Epoch 81/100, Loss: 0.0057, Accuracy: 54.09%\n",
            "Epoch 82/100, Loss: 0.0059, Accuracy: 50.91%\n",
            "Epoch 83/100, Loss: 0.0075, Accuracy: 54.09%\n",
            "Epoch 84/100, Loss: 0.0046, Accuracy: 54.21%\n",
            "Epoch 85/100, Loss: 0.0044, Accuracy: 53.80%\n",
            "Epoch 86/100, Loss: 0.0037, Accuracy: 54.22%\n",
            "Epoch 87/100, Loss: 0.0035, Accuracy: 54.27%\n",
            "Epoch 88/100, Loss: 0.0030, Accuracy: 54.27%\n",
            "Epoch 89/100, Loss: 0.0030, Accuracy: 53.80%\n",
            "Epoch 90/100, Loss: 0.0034, Accuracy: 54.40%\n",
            "Epoch 91/100, Loss: 0.0026, Accuracy: 54.33%\n",
            "Epoch 92/100, Loss: 0.0024, Accuracy: 54.31%\n",
            "Epoch 93/100, Loss: 0.0024, Accuracy: 54.11%\n",
            "Epoch 94/100, Loss: 0.0024, Accuracy: 54.18%\n",
            "Epoch 95/100, Loss: 0.0024, Accuracy: 54.23%\n",
            "Epoch 96/100, Loss: 0.0020, Accuracy: 54.14%\n",
            "Epoch 97/100, Loss: 0.0020, Accuracy: 54.16%\n",
            "Epoch 98/100, Loss: 0.0019, Accuracy: 54.10%\n",
            "Epoch 99/100, Loss: 0.0018, Accuracy: 53.95%\n",
            "Epoch 100/100, Loss: 0.0018, Accuracy: 53.94%\n",
            "Problem 3b Results (Three Hidden Layers):\n",
            "Training Time: 2270.0692205429077 seconds\n",
            "Train Losses (last epoch): 0.0017761932265417189\n",
            "Test Accuracy: 53.94 %\n"
          ]
        }
      ]
    }
  ]
}